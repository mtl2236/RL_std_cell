# RL_std_cell

This program is an reforcement learning program to train an agent that can automaticly generate valid flexible standard cells based on a compact model(Athor:Leilai Shao). First of all, the generated standard cell must have normal logic function. Besides, the PDP(Power Delay Product) is another optimization target which lower is better.

The structure of this whole program is the same as AutoCkt. The reward is extracted from .lib file generated by Cadence Liberate. Due to License constraint, we can temporarily run 5 simulation threads parallelly. 

The reward in each step is defined as follows:
if a cell is failed, its equivalent PDP is defined as -10; If a cell is succeed, its PDP is defined as its average PDP of all the possible logic flips. A step's reward is calculated as the average equivalent PDP of each cell in the library. 

The equivalent PDP is defined as follows:
For all the combinational standard cells, they can be defined as a combination of M NAND2 gates. Therefore, to "normalize" standard cells with different complexity, its equivalent PDP can be defined as its original PDP divided by M. 

Useage:
python autockt/val_autobag_ray.py
